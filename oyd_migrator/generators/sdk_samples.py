"""Python SDK sample code generator."""

from __future__ import annotations

from oyd_migrator.core.constants import MigrationPath


def generate_python_sample(
    agent_name: str,
    project_endpoint: str,
    model: str = "gpt-4.1",
    migration_path: MigrationPath = MigrationPath.SEARCH_TOOL,
    index_name: str | None = None,
    connection_id: str | None = None,
    knowledge_base_name: str | None = None,
) -> str:
    """
    Generate Python SDK sample code for using a migrated agent.

    Args:
        agent_name: Name of the agent
        project_endpoint: Foundry project endpoint URL
        model: Model deployment name
        migration_path: Migration architecture used
        index_name: Search index name (for search tool path)
        connection_id: Connection resource ID
        knowledge_base_name: KB name (for KB path)

    Returns:
        Python code as string
    """
    if migration_path == MigrationPath.SEARCH_TOOL:
        return _generate_search_tool_sample(
            agent_name=agent_name,
            project_endpoint=project_endpoint,
            model=model,
            index_name=index_name or "your-index-name",
            connection_id=connection_id or "your-connection-id",
        )
    else:
        return _generate_knowledge_base_sample(
            agent_name=agent_name,
            project_endpoint=project_endpoint,
            model=model,
            knowledge_base_name=knowledge_base_name or "your-kb-name",
            connection_id=connection_id or "your-mcp-connection-id",
        )


def _generate_search_tool_sample(
    agent_name: str,
    project_endpoint: str,
    model: str,
    index_name: str,
    connection_id: str,
) -> str:
    """Generate sample for Azure AI Search Tool agent."""
    return f'''"""
Azure AI Foundry Agent with Azure AI Search Tool

This sample demonstrates how to use the migrated agent with Azure AI Search
for retrieval-augmented generation (RAG).

Generated by: oyd-foundry-migrator
Agent: {agent_name}
Architecture: Foundry Agent Service + Azure AI Search Tool
"""

import os
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from azure.ai.projects.models import (
    AzureAISearchAgentTool,
    AzureAISearchToolResource,
    AISearchIndexResource,
    AzureAISearchQueryType,
    PromptAgentDefinition,
)

# Configuration
PROJECT_ENDPOINT = "{project_endpoint}"
MODEL_DEPLOYMENT = "{model}"
SEARCH_CONNECTION_ID = "{connection_id}"
INDEX_NAME = "{index_name}"


def main():
    # Initialize credential and client
    credential = DefaultAzureCredential()
    project_client = AIProjectClient(
        endpoint=PROJECT_ENDPOINT,
        credential=credential,
    )

    # Get OpenAI client for conversations
    openai_client = project_client.get_openai_client()

    # Create or get existing agent
    # Note: The agent "{agent_name}" was created during migration
    # You can also create a new agent with the configuration below

    agent_name = "{agent_name}"

    # To create a new agent with the same configuration:
    # search_tool = AzureAISearchAgentTool(
    #     azure_ai_search=AzureAISearchToolResource(
    #         indexes=[
    #             AISearchIndexResource(
    #                 project_connection_id=SEARCH_CONNECTION_ID,
    #                 index_name=INDEX_NAME,
    #                 query_type=AzureAISearchQueryType.VECTOR_SEMANTIC_HYBRID,
    #                 top_k=5,
    #             ),
    #         ]
    #     )
    # )
    #
    # agent = project_client.agents.create_version(
    #     agent_name="my-new-agent",
    #     definition=PromptAgentDefinition(
    #         model=MODEL_DEPLOYMENT,
    #         instructions="You are a helpful assistant. Always cite your sources.",
    #         tools=[search_tool],
    #     ),
    # )

    # Create a conversation
    conversation = openai_client.conversations.create()
    print(f"Created conversation: {{conversation.id}}")

    # Send a query
    user_query = "What information do you have available?"
    print(f"\\nUser: {{user_query}}")

    response = openai_client.responses.create(
        conversation=conversation.id,
        input=user_query,
        extra_body={{
            "agent": {{
                "name": agent_name,
                "type": "agent_reference",
            }},
            "tool_choice": "auto",
        }},
    )

    # Print response
    print(f"\\nAssistant: {{response.output_text}}")

    # Check for citations
    if hasattr(response, "citations") and response.citations:
        print(f"\\nCitations ({{len(response.citations)}}):")
        for i, citation in enumerate(response.citations, 1):
            print(f"  {{i}}. {{citation.get('title', 'Unknown')}}")

    # Continue the conversation
    follow_up = "Can you tell me more about the first topic?"
    print(f"\\nUser: {{follow_up}}")

    response2 = openai_client.responses.create(
        conversation=conversation.id,
        input=follow_up,
        extra_body={{
            "agent": {{
                "name": agent_name,
                "type": "agent_reference",
            }},
        }},
    )

    print(f"\\nAssistant: {{response2.output_text}}")


if __name__ == "__main__":
    main()
'''


def _generate_knowledge_base_sample(
    agent_name: str,
    project_endpoint: str,
    model: str,
    knowledge_base_name: str,
    connection_id: str,
) -> str:
    """Generate sample for Knowledge Base (MCP) agent."""
    return f'''"""
Azure AI Foundry Agent with Foundry IQ Knowledge Base

This sample demonstrates how to use the migrated agent with Foundry IQ
Knowledge Base for advanced retrieval-augmented generation (RAG).

Generated by: oyd-foundry-migrator
Agent: {agent_name}
Architecture: Foundry Agent Service + Foundry IQ Knowledge Base (MCP)
"""

import os
from azure.identity import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from azure.ai.projects.models import (
    MCPTool,
    PromptAgentDefinition,
)

# Configuration
PROJECT_ENDPOINT = "{project_endpoint}"
MODEL_DEPLOYMENT = "{model}"
MCP_CONNECTION_ID = "{connection_id}"
KNOWLEDGE_BASE_NAME = "{knowledge_base_name}"


def main():
    # Initialize credential and client
    credential = DefaultAzureCredential()
    project_client = AIProjectClient(
        endpoint=PROJECT_ENDPOINT,
        credential=credential,
    )

    # Get OpenAI client for conversations
    openai_client = project_client.get_openai_client()

    # The agent "{agent_name}" was created during migration
    agent_name = "{agent_name}"

    # To create a new agent with MCP Knowledge Base:
    # mcp_tool = MCPTool(
    #     server_label="knowledge_base",
    #     server_url="https://your-search.search.windows.net/knowledgebases/{knowledge_base_name}/mcp?api-version=2025-11-01-preview",
    #     require_approval="never",
    #     allowed_tools=["knowledge_base_retrieve"],
    #     project_connection_id=MCP_CONNECTION_ID,
    # )
    #
    # agent = project_client.agents.create_version(
    #     agent_name="my-kb-agent",
    #     definition=PromptAgentDefinition(
    #         model=MODEL_DEPLOYMENT,
    #         instructions=\"""You are a helpful assistant that uses the knowledge base.
    # Always cite your sources and provide accurate information.\""",
    #         tools=[mcp_tool],
    #     ),
    # )

    # Create a conversation
    conversation = openai_client.conversations.create()
    print(f"Created conversation: {{conversation.id}}")

    # Send a query
    user_query = "What information do you have available?"
    print(f"\\nUser: {{user_query}}")

    response = openai_client.responses.create(
        conversation=conversation.id,
        input=user_query,
        extra_body={{
            "agent": {{
                "name": agent_name,
                "type": "agent_reference",
            }},
        }},
    )

    # Print response
    print(f"\\nAssistant: {{response.output_text}}")

    # The Knowledge Base approach provides:
    # - Query planning and decomposition
    # - Multi-technique retrieval (keyword, vector, hybrid)
    # - Semantic reranking
    # - Source attribution with citations

    # Access activity trace for debugging
    if hasattr(response, "activity"):
        print("\\nActivity trace:")
        for activity in response.activity:
            print(f"  - {{activity.get('type', 'unknown')}}: {{activity.get('status', '')}}")

    # Access references/citations
    if hasattr(response, "references"):
        print(f"\\nReferences ({{len(response.references)}}):")
        for ref in response.references:
            print(f"  - {{ref.get('title', ref.get('docKey', 'Unknown'))}}")


if __name__ == "__main__":
    main()
'''
